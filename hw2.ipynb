{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_file(filename):\n",
    "    data_file = open(filename)\n",
    "    dict = {}\n",
    "    for line in data_file:\n",
    "        l = line.split()\n",
    "        docIdx = eval(l[0])\n",
    "        wordIdx = eval(l[1])\n",
    "        count = eval(l[2])\n",
    "        if docIdx not in dict:\n",
    "            dict[docIdx] = defaultdict(int)\n",
    "        dict[docIdx][wordIdx] += count\n",
    "    data_file.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "def read_data_label(filename):\n",
    "    data_file = open(filename)\n",
    "    dict = defaultdict(int)\n",
    "    map = defaultdict(int)\n",
    "\n",
    "    count = 0\n",
    "    for line in data_file:\n",
    "        groupId = eval(line)\n",
    "        dict[groupId] += 1\n",
    "        count += 1\n",
    "        map[count] = groupId\n",
    "    data_file.close()\n",
    "    return dict, map\n",
    "\n",
    "voc_file = open(\"data/vocabulary.txt\")\n",
    "voc_dict = defaultdict(int)\n",
    "count = 0\n",
    "for line in voc_file:\n",
    "    count += 1\n",
    "    voc_dict[count] = line.strip()\n",
    "voc_file.close()\n",
    "\n",
    "train_data = read_data_file(\"data/train.data\")\n",
    "train_label, train_map = read_data_label(\"data/train.label\")\n",
    "\n",
    "group_num = len(train_label)\n",
    "doc_num = len(train_map)\n",
    "voc_num = len(voc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pi = [train_label[groupId] * 1.0 / doc_num for groupId in range(1, 21)]\n",
    "# smoothing\n",
    "p = np.ones((group_num, voc_num))\n",
    "\n",
    "for docId in train_data:\n",
    "    for vId in train_data[docId]:\n",
    "        p[train_map[docId] - 1][vId - 1] += train_data[docId][vId]\n",
    "\n",
    "for groupId in range(len(p)):\n",
    "    group_sum = sum(p[groupId])\n",
    "    for vId in range(len(p[groupId])):\n",
    "        p[groupId][vId] = p[groupId][vId] / group_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# routine groupId: 1 - 20\n",
    "def helper(data, groupId):\n",
    "    result = 0.0\n",
    "    result += math.log(pi[groupId - 1])\n",
    "    for wordId in data:\n",
    "        result += data[wordId] * math.log(p[groupId - 1][wordId - 1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def choose(data):\n",
    "    m = -sys.maxint - 1\n",
    "    result = 0\n",
    "    for groupId in range(1, 21):\n",
    "        temp = helper(data, groupId)\n",
    "        if temp > m:\n",
    "            m = temp\n",
    "            result = groupId\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data = read_data_file(\"data/test.data\")\n",
    "test_label, test_map = read_data_label(\"data/test.label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_num = len(test_map)\n",
    "error_num = 0\n",
    "for docId in test_map:\n",
    "    if choose(test_data[docId]) != test_map[docId]:\n",
    "#         print docId\n",
    "        error_num += 1\n",
    "\n",
    "error_rate = error_num * 1.0 / test_num\n",
    "print \"error_rate \" + str(error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.21892071952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def para(freq_log, remove_stopwords, voc_size, t_data, t_label, t_map, v_data, v_label, v_map):\n",
    "    group_num = len(t_label)\n",
    "    doc_num = len(t_map)\n",
    "    voc_num = voc_size\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    voc_counter = defaultdict(int)\n",
    "    for docId in t_data:\n",
    "        for vocId in t_data[docId]:\n",
    "            voc_counter[vocId] += t_data[docId][vocId]\n",
    "    sorted_voc = sorted(voc_counter.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    voc_indexs = defaultdict(int)\n",
    "    i = 0\n",
    "    for voc in sorted_voc:\n",
    "        if voc_size <= 0:\n",
    "            break\n",
    "        if remove_stopwords and voc_dict[voc[0]] in stop_words:\n",
    "            continue\n",
    "        voc_indexs[i] = voc[0]\n",
    "        i += 1\n",
    "        voc_size -= 1\n",
    "\n",
    "    rev_voc_indexs = {v: k for k, v in voc_indexs.iteritems()}\n",
    "\n",
    "    pi = [t_label[groupId] * 1.0 / doc_num for groupId in range(1, 21)]\n",
    "    p = np.ones((group_num, voc_num))\n",
    "\n",
    "    for docId in t_data:\n",
    "        for v in range(voc_num):\n",
    "            p[t_map[docId] - 1][v] += t_data[docId][voc_indexs[v]]\n",
    "\n",
    "    for groupId in range(len(p)):\n",
    "        group_sum = sum(p[groupId])\n",
    "        for vId in range(len(p[groupId])):\n",
    "            p[groupId][vId] = p[groupId][vId] / group_sum\n",
    "            if freq_log:\n",
    "                p[groupId][vId] = math.log(1 + p[groupId][vId])\n",
    "                      \n",
    "    def helper(data, groupId):\n",
    "        result = 0.0\n",
    "        result += math.log(pi[groupId - 1])\n",
    "        for wordId in data:\n",
    "            if wordId in rev_voc_indexs:\n",
    "                result += data[wordId] * math.log(p[groupId - 1][rev_voc_indexs[wordId]])\n",
    "        return result\n",
    "\n",
    "    def choose(data):\n",
    "        m = -sys.maxint - 1\n",
    "        result = 0\n",
    "        for groupId in range(1, 21):\n",
    "            temp = helper(data, groupId)\n",
    "            if temp > m:\n",
    "                m = temp\n",
    "                result = groupId\n",
    "        return result\n",
    "\n",
    "    v_num = len(v_map)\n",
    "    error_num = 0\n",
    "    for docId in v_map:\n",
    "        if choose(v_data[docId]) != v_map[docId]:\n",
    "            error_num += 1\n",
    "\n",
    "    error_rate = error_num * 1.0 / v_num\n",
    "                      \n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"False, False, 10000 \", para(False, False, 10000)\n",
    "print \"False, True, 10000 \", para(False, True, 10000)\n",
    "print \"True, False, 10000 \", para(True, False, 10000)\n",
    "print \"True, True, 10000 \", para(True, True, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False, False, 10000  error_rate 0.160603371783\n",
    "\n",
    "False, True, 10000  error_rate 0.157497781721\n",
    "\n",
    "True, False, 10000  error_rate 0.160603371783\n",
    "\n",
    "True, True, 10000  error_rate 0.157941437445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"False, True, 500 \", para(False, True, 500)\n",
    "print \"False, True, 1000 \", para(False, True, 1000)\n",
    "print \"False, True, 2000 \", para(False, True, 2000)\n",
    "print \"False, True, 3000 \", para(False, True, 3000)\n",
    "print \"False, True, 5000 \", para(False, True, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False, True, 500  error_rate 0.416149068323\n",
    "\n",
    "False, True, 1000  error_rate 0.326530612245\n",
    "\n",
    "False, True, 2000  error_rate 0.251552795031\n",
    "\n",
    "False, True, 3000  error_rate 0.217391304348\n",
    "\n",
    "False, True, 5000  error_rate 0.188997338066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_indexs = random.sample(range(1, doc_num + 1), doc_num * 8 / 10)\n",
    "train_indexs.sort()\n",
    "validation_indexs = [i for i in range(1, doc_num + 1) if i not in train_indexs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_data = {}\n",
    "t_label = defaultdict(int)\n",
    "t_map = {}\n",
    "v_data = {}\n",
    "v_label = defaultdict(int)\n",
    "v_map = {}\n",
    "\n",
    "for docId in train_data:\n",
    "    if docId in train_indexs:\n",
    "        t_data[docId] = train_data[docId]\n",
    "        t_map[docId] = train_map[docId]\n",
    "        t_label[train_map[docId]] += 1\n",
    "    else:\n",
    "        v_data[docId] = train_data[docId]\n",
    "        v_map[docId] = train_map[docId]\n",
    "        v_label[train_map[docId]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"False, True, 8000 \", para(False, True, 8000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 15000 \", para(False, True, 15000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 20000 \", para(False, True, 20000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 30000 \", para(False, True, 30000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 50000 \", para(False, True, 50000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 70000 \", para(False, True, 70000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 100000 \", para(False, True, 100000, t_data, t_label, t_map, v_data, v_label, v_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False, True, 8000  0.16149068323\n",
    "\n",
    "False, True, 15000  0.143744454303\n",
    "\n",
    "False, True, 20000  0.139307897072\n",
    "\n",
    "False, True, 30000  0.132653061224\n",
    "\n",
    "False, True, 35000  0.131765749778\n",
    "\n",
    "False, True, 40000  0.131322094055\n",
    "\n",
    "False, True, 45000  0.130434782609\n",
    "\n",
    "False, True, 50000  0.132209405501\n",
    "\n",
    "False, True, 55000  0.135314995563\n",
    "\n",
    "False, True, 60000  0.136645962733\n",
    "\n",
    "False, True, 65000  0.137976929902\n",
    "\n",
    "False, True, 70000  0.140195208518\n",
    "\n",
    "False, True, 100000  0.145075421473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False, True, 44000  0.134427684117\n",
      "False, True, 46000  0.133984028394\n",
      "False, True, 43000 "
     ]
    }
   ],
   "source": [
    "print \"False, True, 44000 \", para(False, True, 44000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 46000 \", para(False, True, 46000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 43000 \", para(False, True, 43000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 47000 \", para(False, True, 47000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 42000 \", para(False, True, 42000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 48000 \", para(False, True, 48000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 41000 \", para(False, True, 41000, t_data, t_label, t_map, v_data, v_label, v_map)\n",
    "print \"False, True, 49000 \", para(False, True, 49000, t_data, t_label, t_map, v_data, v_label, v_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"True, True, 61188 \", para(True, True, 61188, train_data, train_label, train_map, test_data, test_label, test_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
